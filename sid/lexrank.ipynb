{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Using cached sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (3.8.1)\n",
      "Collecting indic-nlp-library\n",
      "  Using cached indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting breadability>=0.1.20 (from sumy)\n",
      "  Using cached breadability-0.1.20.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from sumy) (2.32.2)\n",
      "Collecting pycountry>=18.2.23 (from sumy)\n",
      "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.4)\n",
      "Collecting sphinx-argparse (from indic-nlp-library)\n",
      "  Using cached sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
      "  Using cached sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting morfessor (from indic-nlp-library)\n",
      "  Using cached Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from indic-nlp-library) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from indic-nlp-library) (1.26.4)\n",
      "Requirement already satisfied: chardet in /opt/anaconda3/lib/python3.12/site-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
      "Requirement already satisfied: lxml>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from breadability>=0.1.20->sumy) (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->indic-nlp-library) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->indic-nlp-library) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->indic-nlp-library) (2023.3)\n",
      "Requirement already satisfied: sphinx>=5.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx-argparse->indic-nlp-library) (7.3.7)\n",
      "Collecting docutils>=0.19 (from sphinx-argparse->indic-nlp-library)\n",
      "  Using cached docutils-0.22.2-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
      "  Using cached sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.1.10)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.4)\n",
      "Requirement already satisfied: Pygments>=2.14 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.15.1)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.11.0)\n",
      "Requirement already satisfied: alabaster~=0.7.14 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (0.7.16)\n",
      "Requirement already satisfied: imagesize>=1.3 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21.0 in /opt/anaconda3/lib/python3.12/site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (23.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from Jinja2>=3.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.3)\n",
      "Using cached sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "Using cached indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
      "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "Using cached Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
      "Using cached sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
      "Using cached sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
      "Using cached docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "Using cached sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "Building wheels for collected packages: breadability, docopt\n",
      "  Building wheel for breadability (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21694 sha256=8892d99a7689d7ae052b215eecce91e04aadc22fe214419374059a6fb35c2747\n",
      "  Stored in directory: /Users/siddheshrangnekar/Library/Caches/pip/wheels/32/99/64/59305409cacd03aa03e7bddf31a9db34b1fa7033bd41972662\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=f0c38c388dd02171afc67c1c6268f1b82ed1abd76c7ecc7690e7d7c0de4d9192\n",
      "  Stored in directory: /Users/siddheshrangnekar/Library/Caches/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "Successfully built breadability docopt\n",
      "Installing collected packages: morfessor, docopt, pycountry, docutils, breadability, sumy, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.18.1\n",
      "    Uninstalling docutils-0.18.1:\n",
      "      Successfully uninstalled docutils-0.18.1\n",
      "Successfully installed breadability-0.1.20 docopt-0.6.2 docutils-0.21.2 indic-nlp-library-0.92 morfessor-2.0.6 pycountry-24.6.1 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1 sumy-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sumy nltk indic-nlp-library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/siddheshrangnekar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/siddheshrangnekar/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install required libraries if not already installed\n",
    "# pip install sumy nltk\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")   # NEW fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Extractive Summary (LexRank) ===\n",
      "\n",
      "Today, we are here to discuss ways to improve sales in rural markets.\n",
      "The main points of the previous meeting were: we approved the changes in our sales reporting system discussed on May 30th.\n",
      "A copy of the main ideas discussed is in the photocopies in front of you.\n",
      "Rural customers need special help to feel valued; Our sales teams need more accurate and detailed customer information; A survey will be conducted to gather data on spending habits in these areas; The survey results will be provided to the sales teams; We are considering advanced data mining techniques to deepen understanding.\n",
      "Finally, the meeting organizer confirmed that the main agenda items were covered, asked if there was any other business, and discussed scheduling the next meeting.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Load Hindi text\n",
    "with open(\"Sid.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Step 2: Hindi stopwords\n",
    "english_stopwords = set([\n",
    "    \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\",\n",
    "    \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\",\n",
    "    \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\",\n",
    "    \"doesn't\", \"doing\", \"don't\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn't\", \"has\",\n",
    "    \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he's\", \"her\", \"here\", \"hers\", \"herself\", \"him\",\n",
    "    \"himself\", \"his\", \"how\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\",\n",
    "    \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\",\n",
    "    \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\",\n",
    "    \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she's\", \"should\", \"shouldn't\", \"so\",\n",
    "    \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\",\n",
    "    \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\",\n",
    "    \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\",\n",
    "    \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "    \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\",\n",
    "    \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"\n",
    "]);\n",
    "\n",
    "# Step 3: Word Tokenization + Stopword Removal\n",
    "words = word_tokenize(text)  \n",
    "filtered_words = [w for w in words if w not in english_stopwords]\n",
    "filtered_text = \" \".join(filtered_words)\n",
    "\n",
    "# Step 4: Use LexRank summarizer (works at sentence level)\n",
    "parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "summarizer = LexRankSummarizer()\n",
    "\n",
    "summary_sentences = 5\n",
    "summary = summarizer(parser.document, summary_sentences)\n",
    "\n",
    "# Step 5: Print summary\n",
    "print(\"=== Extractive Summary (LexRank) ===\\n\")\n",
    "for sentence in summary:\n",
    "    print(str(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
